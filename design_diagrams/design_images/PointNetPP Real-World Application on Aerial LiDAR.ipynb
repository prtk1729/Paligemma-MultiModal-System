{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"vscode":{"languageId":"shellscript"},"id":"EN1jU5OfHfEK"},"outputs":[],"source":["!pip install cuda-python\n","!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n","!pip install matplotlib scipy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MisKPLV6HfEN","outputId":"3ae1ed66-5d85-484b-9419-64ec70070b62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Charging on NVIDIA GeForce RTX 3060 Ti\n"]}],"source":["# setup:\n","import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n","# Verify CUDA's embrace\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print(f\"Charging on {torch.cuda.get_device_name(0)}\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Marching on the CPU\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0cSWcQpHfEO","outputId":"c63bc0d7-ec6f-40d0-d7b9-0da150716621"},"outputs":[{"name":"stdout","output_type":"stream","text":["Jupyter environment detected. Enabling Open3D WebVisualizer.\n","[Open3D INFO] WebRTC GUI backend enabled.\n","[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"]}],"source":["import os, random, numpy as np, open3d as o3d\n","import pickle\n","from glob import glob\n","from typing import Tuple, Dict, Any\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from torch.utils.data import DataLoader, Dataset\n","import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n","import copy\n","from scipy.spatial import KDTree\n","from itertools import product"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcMBF-43HfEO"},"outputs":[],"source":["from m02_code import CustomDataset,infer_point_clouds"]},{"cell_type":"code","source":["def train_and_save_model(device,train_loader,val_loader, num_classes,model, save_path=\"model.pth\",  epochs = 100):\n","    criterion = nn.CrossEntropyLoss(ignore_index=-1)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    for epoch in range(epochs):\n","        model.train()\n","        for batch in train_loader:\n","            inputs, labels,index = batch\n","            p =inputs\n","            p, labels = p.float(), labels.long()\n","            p, labels = p.to(device), labels.to(device)\n","            seg_pred = model(p)\n","            seg_pred = seg_pred.contiguous().view(-1, num_classes)\n","            labels = labels.view(-1, 1)[:, 0]\n","            loss = criterion(seg_pred, labels)\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","        model.eval()\n","        total_correct = 0\n","        total_points = 0\n","        with torch.no_grad():\n","            for batch in val_loader:\n","                inputs, labels,index = batch\n","                p =inputs\n","                p, labels = p.float(), labels.long()\n","                p, labels = p.to(device), labels.to(device)\n","                seg_pred = model(p)\n","                seg_pred = seg_pred.contiguous().view(-1, num_classes)\n","                labels = labels.view(-1, 1)[:, 0]\n","                _, predicted = seg_pred.max(1)\n","                total_correct += (predicted == labels).sum().item()\n","                total_points += labels.size(0)\n","        accuracy = 100 * total_correct / total_points\n","        print(f\"Epoch [{epoch+1}/{epochs}], Loss {loss:.4f}, Accuracy: {accuracy:.2f}%\")\n","    torch.save(model.state_dict(), save_path)"],"metadata":{"id":"ukmpbj2yIXiY"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VvvOFveHfEP"},"outputs":[],"source":["def square_distance(src,dst):\n","    B,N,_=src.shape\n","    _,M,_=dst.shape\n","    dist=-2*torch.matmul(src,dst.permute(0,2,1))\n","    dist+=torch.sum(src**2,-1).view(B,N,1)\n","    dist+=torch.sum(dst**2,-1).view(B,1,M)\n","    return dist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqOi5IJHHfEP"},"outputs":[],"source":["def index_points(points,idx):\n","    device=points.device\n","    B=points.shape[0]\n","    view_shape=list(idx.shape)\n","    view_shape[1:]=[1]*(len(view_shape)-1)\n","    repeat_shape=list(idx.shape)\n","    repeat_shape[0]=1\n","    batch_indices=torch.arange(B,dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n","    new_points=points[batch_indices,idx,:]\n","    return new_points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyCTlMFnHfEP"},"outputs":[],"source":["def farthest_point_sample(xyz,npoint):\n","    device=xyz.device\n","    B,N,C=xyz.shape\n","    centroids=torch.zeros(B,npoint,dtype=torch.long).to(device)\n","    distance=torch.ones(B,N).to(device)*1e10\n","    farthest=torch.randint(0,N,(B,),dtype=torch.long).to(device)\n","    batch_indices=torch.arange(B,dtype=torch.long).to(device)\n","    for i in range(npoint):\n","        centroids[:,i]=farthest\n","        centroid=xyz[batch_indices,farthest,:].view(B,1,3)\n","        dist=torch.sum((xyz-centroid)**2,-1)\n","        mask=dist<distance\n","        distance[mask]=dist[mask]\n","        farthest=torch.max(distance,-1)[1]\n","    return centroids"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4Et0WEpHfEQ"},"outputs":[],"source":["def query_ball_point(radius,nsample,xyz,new_xyz):\n","    device=xyz.device\n","    B,N,C=xyz.shape\n","    _,S,_=new_xyz.shape\n","    group_idx=torch.arange(N,dtype=torch.long).to(device).view(1,1,N).repeat([B,S,1])\n","    sqrdists=square_distance(new_xyz,xyz)\n","    group_idx[sqrdists>radius**2]=N\n","    group_idx=group_idx.sort(dim=-1)[0][:,:,:nsample]\n","    group_first=group_idx[:,:,0].view(B,S,1).repeat([1,1,nsample])\n","    mask=group_idx==N\n","    group_idx[mask]=group_first[mask]\n","    return group_idx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOSsZjLGHfEQ"},"outputs":[],"source":["def sample_and_group(npoint,radius,nsample,xyz,points,returnfps=False):\n","    B,N,C=xyz.shape\n","    S=npoint\n","    fps_idx=farthest_point_sample(xyz,npoint)\n","    new_xyz=index_points(xyz,fps_idx)\n","    idx=query_ball_point(radius,nsample,xyz,new_xyz)\n","    groupe_xyz=index_points(xyz,idx)\n","    groupe_xyz_norm=groupe_xyz-new_xyz.view(B,S,1,C)\n","\n","    if points is not None:\n","        grouped_points=index_points(points,idx)\n","        new_points=torch.cat([groupe_xyz_norm,grouped_points],dim=-1)\n","    else:\n","        new_points=groupe_xyz_norm\n","    if returnfps:\n","        return new_xyz,new_points,groupe_xyz,fps_idx\n","    else:\n","        return new_xyz,new_points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFWWP-jiHfEQ"},"outputs":[],"source":["def sample_and_group_all(xyz,points):\n","    device=xyz.device\n","    B,N,C=xyz.shape\n","    new_xyz=torch.zeros(B,1,C).to(device)\n","    grouped_xyz=xyz.view(B,1,N,C)\n","    if points is not None:\n","        new_points=torch.cat([grouped_xyz,points.view(B,1,N,-1)],dim=-1)\n","    else:\n","        new_points=grouped_xyz\n","    return new_xyz,new_points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kOnUMDX-HfER"},"outputs":[],"source":["class PointNetSetAbstraction(nn.Module):\n","    def __init__(self,npoint,radius,nsample,in_channel,mlp,group_all) -> None:\n","        super(PointNetSetAbstraction,self).__init__()\n","        self.npoint=npoint\n","        self.radius=radius\n","        self.nsample=nsample\n","        self.mlp_convs=nn.ModuleList()\n","        self.mlp_bns=nn.ModuleList()\n","        last_channel=in_channel\n","        for out_channel in mlp:\n","            self.mlp_convs.append(nn.Conv2d(last_channel,out_channel,1))\n","            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n","            last_channel=out_channel\n","        self.group_all=group_all\n","\n","    def forward(self,xyz,points):\n","        xyz=xyz.permute(0,2,1)\n","        if points is not None:\n","            points=points.permute(0,2,1)\n","        if self.group_all:\n","            new_xyz,new_points=sample_and_group(xyz,points)\n","        else:\n","            new_xyz,new_points=sample_and_group(self.npoint,self.radius,self.nsample,xyz,points)\n","        new_points=new_points.permute(0,3,2,1)\n","        for i,conv in enumerate(self.mlp_convs):\n","            bn=self.mlp_bns[i]\n","            new_points=F.relu(bn(conv(new_points)))\n","        new_points=torch.max(new_points,2)[0]\n","        new_xyz=new_xyz.permute(0,2,1)\n","        return new_xyz,new_points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xWGRMAp3HfER"},"outputs":[],"source":["class PointNetFeaturePropagation(nn.Module):\n","    def __init__(self, in_channel,mlp) -> None:\n","        super(PointNetFeaturePropagation,self).__init__()\n","        self.mlp_convs=nn.ModuleList()\n","        self.mlp_bns=nn.ModuleList()\n","        last_channel=in_channel\n","        for out_channel in mlp:\n","            self.mlp_convs.append(nn.Conv1d(last_channel,out_channel,1))\n","            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n","            last_channel=out_channel\n","\n","    def forward(self,xyz1,xyz2,points1,points2):\n","        xyz1=xyz1.permute(0,2,1)\n","        xyz2=xyz2.permute(0,2,1)\n","\n","        points2=points2.permute(0,2,1)\n","        B,N,C=xyz1.shape\n","        _,S,_=xyz2.shape\n","\n","        if S==1:\n","            interpolated_points=points2.repeat(1,N,1)\n","        else:\n","            dists=square_distance(xyz1,xyz2)\n","            dists,idx=dists.sort(dim=-1)\n","            dists,idx=dists[:,:,:3],idx[:,:,:3]\n","            dist_recip=1.0/(dists+1e-8)\n","            norm=torch.sum(dist_recip,dim=2,keepdim=True)\n","            weight=dist_recip/norm\n","            interpolated_points=torch.sum(index_points(points2,idx)*weight.view(B,N,3,1),dim=2)\n","        if points1 is not None:\n","            points1=points1.permute(0,2,1)\n","            new_points=torch.cat([points1,interpolated_points],dim=-1)\n","        else:\n","            new_points=interpolated_points\n","        new_points=new_points.permute(0,2,1)\n","        for i, conv in enumerate(self.mlp_convs):\n","            bn=self.mlp_bns[i]\n","            new_points=F.relu(bn(conv(new_points)))\n","        return new_points"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YSr8leACHfER"},"outputs":[],"source":["class PointNet2(nn.Module):\n","    def __init__(self, num_classes) -> None:\n","        super(PointNet2,self).__init__()\n","\n","        self.sa1=PointNetSetAbstraction(1024,0.1,32,3+3,[32,32,64],False)\n","        self.sa2=PointNetSetAbstraction(256,0.2,32,64+3,[64,64,128],False)\n","        self.sa3=PointNetSetAbstraction(64,0.4,32,128+3,[128,128,256],False)\n","        self.sa4=PointNetSetAbstraction(16,0.8,32,256+3,[256,256,512],False)\n","\n","        self.fp4=PointNetFeaturePropagation(768,[256,256])\n","        self.fp3=PointNetFeaturePropagation(384,[256,256])\n","        self.fp2=PointNetFeaturePropagation(320,[256,128])\n","        self.fp1=PointNetFeaturePropagation(128,[256,128,128])\n","\n","        self.conv1=nn.Conv1d(128,128,1)\n","        self.bn1=nn.BatchNorm1d(128)\n","        self.drop1=nn.Dropout(0.5)\n","        self.conv2=nn.Conv1d(128,num_classes,1)\n","    def forward(self,xyz):\n","        l1_xyz,l1_points=self.sa1(xyz,xyz)\n","        l2_xyz,l2_points=self.sa2(l1_xyz,l1_points)\n","        l3_xyz,l3_points=self.sa3(l2_xyz,l2_points)\n","        l4_xyz,l4_points=self.sa4(l3_xyz,l3_points)\n","\n","        l3_points=self.fp4(l3_xyz,l4_xyz,l3_points,l4_points)\n","        l2_points=self.fp3(l2_xyz,l3_xyz,l2_points,l3_points)\n","        l1_points=self.fp2(l1_xyz,l2_xyz,l1_points,l2_points)\n","        l0_points=self.fp1(xyz,l1_xyz,None,l1_points)\n","\n","        x=self.drop1(F.relu(self.bn1(self.conv1(l0_points))))\n","        x=self.conv2(x)\n","        x=F.log_softmax(x,dim=1)\n","        x=x.permute(0,2,1)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YL-ZdSBSHfER"},"outputs":[],"source":["project_dir = '../../../data/AHN4_34EN2_18'\n","pointcloud_train_files=glob(os.path.join(project_dir,\"strain/*.txt\"))\n","pointcloud_test_files=glob(os.path.join(project_dir,\"stest/*.txt\"))\n","valid_index=np.random.choice(len(pointcloud_train_files),int(len(pointcloud_train_files)/5),replace=False)\n","valid_list=[pointcloud_train_files[i]for i in valid_index]\n","train_list=[pointcloud_train_files[i]for i in np.setdiff1d(list(range(len(pointcloud_train_files))), valid_index)]\n","test_list=pointcloud_test_files\n","num_point=4096\n","train_dataset=CustomDataset(train_list,\"xyz\",num_point=num_point)\n","train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True)\n","val_dataset=CustomDataset(valid_list,\"xyz\",is_training=False,num_point=num_point)\n","val_loader=DataLoader(val_dataset,batch_size=32,shuffle=True)\n","test_dataset=CustomDataset(test_list,\"xyz\",is_training=False,has_ground_trust=False,num_point=num_point)\n","test_loader=DataLoader(test_dataset,batch_size=32,shuffle=True)\n","print(train_dataset.num_classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_5runrCQHfER"},"outputs":[],"source":["model=PointNet2(num_classes=train_dataset.num_classes)\n","model.to(device)\n","train_and_save_model(device,train_loader,val_loader,num_classes=train_dataset.num_classes,model=model,save_path=\"pnet2.pht\",epochs=100)"]},{"cell_type":"markdown","metadata":{"id":"JWLWIlKNHfER"},"source":["---\n","\n","## Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"McD5CzCtHfES"},"outputs":[],"source":["num_classes=train_dataset.num_classes\n","model=PointNet2(num_classes)\n","model.load_state_dict(torch.load(\"pnet2.pht\"))\n","model.to(device)\n","test_prediction=infer_point_clouds(device,model,test_loader,num_classes)\n","print(test_prediction.shape)\n","resulting_point_cloud=np.vstack(test_prediction)\n","print(resulting_point_cloud.shape)\n","np.savetxt(\"results.txt\",resulting_point_cloud,fmt=\"%.6f %.6f %.6f %d\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUHzozoEHfET"},"outputs":[],"source":["label_mapping=test_dataset.label_mapping\n","num_unique_labels=len(label_mapping.keys())\n","colormap=np.random.random((num_unique_labels,3))\n","\n","points=resulting_point_cloud[:,:3]\n","labels=resulting_point_cloud[:,-1]\n","colors=colormap[labels.astype(int)-1]\n","pcd=o3d.geometry.PointCloud()\n","pcd.points=o3d.utility.Vector3dVector(points)\n","pcd.colors=o3d.utility.Vector3dVector(colors)\n","pcd.estimate_normals()\n","\n","o3d.visualization.draw_geometries([pcd])"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}